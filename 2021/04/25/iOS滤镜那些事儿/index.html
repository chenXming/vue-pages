<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>iOS滤镜那些事儿 | chenXming的技术博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="一. GPUImage 框架的介绍及基本使用1.GPUImage 的介绍  GPUImage是基于OpenGL ES的一套图像、视频处理开源框架，它里面提供了大量的滤镜，使用者可以通过这些滤镜的组合实现很好的效果，同时也很方便在原有基础上实现自定义的滤镜。对于大规模并行操作（如处理图像或实时视频帧），GPU具有比CPU更显着的性能优势。而 GPUImage 所有滤镜是基于OpenGL Shader">
<meta property="og:type" content="article">
<meta property="og:title" content="iOS滤镜那些事儿">
<meta property="og:url" content="https://chenxming.github.io/vue-pages/2021/04/25/iOS%E6%BB%A4%E9%95%9C%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/index.html">
<meta property="og:site_name" content="chenXming的技术博客">
<meta property="og:description" content="一. GPUImage 框架的介绍及基本使用1.GPUImage 的介绍  GPUImage是基于OpenGL ES的一套图像、视频处理开源框架，它里面提供了大量的滤镜，使用者可以通过这些滤镜的组合实现很好的效果，同时也很方便在原有基础上实现自定义的滤镜。对于大规模并行操作（如处理图像或实时视频帧），GPU具有比CPU更显着的性能优势。而 GPUImage 所有滤镜是基于OpenGL Shader">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/04/19/ORQtClgUzNJPyj2.png">
<meta property="og:image" content="https://i.loli.net/2021/04/19/SOLKPabrFE2okIM.png">
<meta property="og:image" content="https://i.loli.net/2021/04/20/Hh4ltZmq3gxapL1.png">
<meta property="og:image" content="https://i.loli.net/2021/04/25/tqfzpyXRsLCEOUv.gif">
<meta property="og:image" content="https://i.loli.net/2021/04/25/i3n5zfF8POqR4EG.gif">
<meta property="og:image" content="https://i.loli.net/2021/04/19/eZsjc9pNyTGOlzW.png">
<meta property="og:image" content="https://i.loli.net/2021/04/21/hu3EyHDFx8voZWq.png">
<meta property="og:image" content="https://i.loli.net/2021/04/25/EFdt6xioV8rGTbw.gif">
<meta property="article:published_time" content="2021-04-25T12:11:19.000Z">
<meta property="article:modified_time" content="2022-12-26T08:47:17.035Z">
<meta property="article:author" content="chenXming">
<meta property="article:tag" content="chenXming,xiaoming">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/04/19/ORQtClgUzNJPyj2.png">
  
    <link rel="alternate" href="/vue-pages/atom.xml" title="chenXming的技术博客" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/vue-pages/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/vue-pages/css/style.css">

  
    
<link rel="stylesheet" href="/vue-pages/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/vue-pages/" id="logo">chenXming的技术博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/vue-pages/" id="subtitle">chenXming的技术博客，记录开发中用到的iOS客户端与前端技术</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/vue-pages/">Home</a>
        
          <a class="main-nav-link" href="/vue-pages/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/vue-pages/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://chenxming.github.io/vue-pages"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-iOS滤镜那些事儿" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/vue-pages/2021/04/25/iOS%E6%BB%A4%E9%95%9C%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/" class="article-date">
  <time class="dt-published" datetime="2021-04-25T12:11:19.000Z" itemprop="datePublished">2021-04-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      iOS滤镜那些事儿
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="一-GPUImage-框架的介绍及基本使用"><a href="#一-GPUImage-框架的介绍及基本使用" class="headerlink" title="一. GPUImage 框架的介绍及基本使用"></a>一. <code>GPUImage</code> 框架的介绍及基本使用</h3><h4 id="1-GPUImage-的介绍"><a href="#1-GPUImage-的介绍" class="headerlink" title="1.GPUImage 的介绍"></a>1.<code>GPUImage</code> 的介绍</h4><p>  GPUImage是基于<code>OpenGL ES</code>的一套图像、视频处理开源框架，它里面提供了大量的滤镜，使用者可以通过这些滤镜的组合实现很好的效果，同时也很方便在原有基础上实现自定义的滤镜。对于大规模并行操作（如处理图像或实时视频帧），GPU具有比CPU更显着的性能优势。而 GPUImage 所有滤镜是基于<code>OpenGL Shader</code>实现的，所以滤镜效果、图像处理是在GPU上执行的，处理效率比较高，在iPhone4及其以上手机，可以做到实时流畅的效果。而且它隐藏了<code>Objective-C</code>与<code>OpenGL ES</code> API交互的复杂性。目前市面上的图像视频处理App，95%以上在使用GPUImage，所以学习它的使用及原理还是很有必要的。GPUImage 同时支持iOS跟Andorid平台，地址：<a target="_blank" rel="noopener" href="https://github.com/BradLarson/GPUImage">iOS版本</a> <a target="_blank" rel="noopener" href="https://github.com/cats-oss/android-gpuimage/blob/master/README.md">Android版本</a> 也支持 <a target="_blank" rel="noopener" href="https://github.com/BradLarson/GPUImage2">Swift版本</a>，本文主要介绍它的 OC 版本，核心类的功能以及原理跟 Andorid 版本是相通的。<br>iOS开发者使用方式：直接 CocaPods 集成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pod &#x27;GPUImage&#x27;</span><br></pre></td></tr></table></figure>
<p>首先来看下它的基本结构图：<img src="https://i.loli.net/2021/04/19/ORQtClgUzNJPyj2.png" alt="架构图"></p>
<p>从这张图中我们可以看到GPUImage的几个核心类:<code>GPUImageOutput</code> <code>GPUImageFilter</code> <code>GPUImageInput 协议</code> <code>GPUImageFrameBuffer</code>,接下来我们重点讲解这几个类。</p>
<h4 id="2-核心功能类说明"><a href="#2-核心功能类说明" class="headerlink" title="2.核心功能类说明"></a>2.核心功能类说明</h4><h5 id="GPUImageOutput"><a href="#GPUImageOutput" class="headerlink" title="GPUImageOutput"></a><code>GPUImageOutput</code></h5><p>  <code>GPUImageOutput</code> 是所有滤镜输入源的基类，也就是滤镜链的起点，先看下他的继承关系：</p>
<p><img src="https://i.loli.net/2021/04/19/SOLKPabrFE2okIM.png" alt="GPUImageOutput"><br><br>分别解释一下这几种类型：<br></p>
<ul>
<li><code>GPUImagePicture</code><br>通过图片来初始化，本质上是先将图片转化为 CGImageRef，然后将 CGImageRef 转化为纹理。<br></li>
<li><code>GPUImageVideoCamera</code>:通过相机来初始化,本质是封装了AVCaptureVideoDataOutput来获取持续的视频流数据输出，在代理方法<code>captureOutput:didOutputSampleBuffer:fromConnection:</code>拿到 CMSampleBufferRef，将其转化为纹理的过程。<code>GPUImageStillCamera</code>是 GPUImageVideoCamera 的子类，可以用它来实现拍照功能。<br></li>
<li><code>GPUImageUIElement</code>:可以通过 UIView 或者 CALayer 来初始化。这个类可以用来实现在视频上添加文字水印的功能。<br></li>
<li><code>GPUImageTextureInput</code>:通过已经存在的纹理来初始化.<br></li>
<li><code>GPUImageRawDataInput</code>:通过二进制数据初始化，然后将二进制数据转化为纹理.<br></li>
<li><code>GPUImageMovie</code>:通过本地的视频来初始化。首先通过 AVAssetReader 来逐帧读取视频,然后将帧数据转化为纹理。</li>
<li><code>GPUImageFilter</code>:比较特殊，它既继承自 GPUImageOutput,又遵守协议 GPUImageInput 协议,所以它既可以作为滤镜链的源头，又可以把渲染的纹理输出给遵守 GPUImageInput 协议的类。是滤镜的核心，后面会单独介绍。<br></li>
</ul>
<h6 id="核心功能与方法："><a href="#核心功能与方法：" class="headerlink" title="核心功能与方法："></a>核心功能与方法：</h6><p>想象一下，一个滤镜链的源头能做什么呢：</p>
<ol>
<li>需要产出一个渲染对象，这个需要渲染的对象就是<code>GPUImageFrameBuffer</code>.几个关于frameBuffer的方法：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (GPUImageFramebuffer *)framebufferForOutput;</span><br></pre></td></tr></table></figure>
<p>这个方法可以获得当前正在渲染的frameBuffer</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (void)removeOutputFramebuffer;</span><br></pre></td></tr></table></figure>
<p>这个方法用来移除当前渲染的frameBuffer</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (void)setInputFramebufferForTarget:(id&lt;GPUImageInput&gt;)target atIndex:(NSInteger)inputTextureIndex;</span><br></pre></td></tr></table></figure>
<p>这个方法的调用发生在当前output渲染完毕后，需要通知下一个receiver可以开始渲染的时候，把当前Output的FrameBuffer传递给下一个Input，让它可以使用这个FrameBuffer的结果进行渲染。</p>
<ol start="2">
<li>Target的添加以及管理，用来生成整个FilterChain.<br><br>GPUImageOutput 既然作为一个滤镜的源头，相对应的就得有接受者接受它输出的 FrameBuffer ,这些接受者就是Target,而且有可能有多个接受者。管理这些target的主要方法：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- (void)addTarget:(id&lt;GPUImageInput&gt;)newTarget;</span><br><span class="line">- (void)addTarget:(id&lt;GPUImageInput&gt;)newTarget atTextureLocation:(NSInteger)textureLocation;</span><br></pre></td></tr></table></figure>
这两个addTarget方法的作用都是将下一个实现了GPUImageInput协议的对象添加到FilterChain当中来.一旦添加到滤镜链后，在当前Output渲染完成后就会收到通知，从而进行下一步的处理。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (NSArray*)targets;</span><br></pre></td></tr></table></figure>
<p>每个Output都可以添加多个target,这个方法可以获取到当前Output所有的target.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- (void)removeTarget:(id&lt;GPUImageInput&gt;)targetToRemove;</span><br><span class="line">- (void)removeAllTargets;</span><br></pre></td></tr></table></figure>
<p>这两个方法的作用是将某一个或者所有的target都移出FilterChain。当一个target被移出FilterChain之后，它将不会再收到任何当前Output渲染完成的通知。</p>
<ol start="3">
<li>获取当前的GPUImageOutput对FrameBuffer的处理结果<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- (CGImageRef)newCGImageFromCurrentlyProcessedOutput;</span><br><span class="line">- (CGImageRef)newCGImageByFilteringCGImage:(CGImageRef)imageToFilter;</span><br><span class="line">- (UIImage *)imageFromCurrentFramebuffer;</span><br><span class="line">- (UIImage *)imageFromCurrentFramebufferWithOrientation:(UIImageOrientation)imageOrientation;</span><br><span class="line">- (UIImage *)imageByFilteringImage:(UIImage *)imageToFilter;</span><br><span class="line">- (CGImageRef)newCGImageByFilteringImage:(UIImage *)imageToFilter;</span><br></pre></td></tr></table></figure>
其中最核心的方法是<code>newCGImageFromCurrentlyProcessedOutput</code>，基本上所有的方法最终都调用了这个方法。但是GPUImageOutput并没有为这个方法提供默认的实现，而是提供了一个方法定义。具体的实现在它的两个重要的子类 GPUImageFilter 和 GPUImageFilterGroup 中。而实际上最终调用的方法都在 GPUImageFilter 中实现了.</li>
</ol>
<h5 id="GPUImageInput协议"><a href="#GPUImageInput协议" class="headerlink" title="GPUImageInput协议"></a><code>GPUImageInput</code>协议</h5><p> <code>GPUImageInput</code> 是一个协议，它定义了一个能够接收 FrameBuffer 的 receiver 所必须实现的基本功能。实现这个协议的类可以作为渲染的终点使用。<br>实现了 GPUImageInput 接口的类：</p>
<p><img src="https://i.loli.net/2021/04/20/Hh4ltZmq3gxapL1.png" alt="GPUImageInput协议"><br>对这几个类进行解释：<br></p>
<ul>
<li><code>GPUImageMovieWriter</code>：封装了 AVAssetWriter，可以逐帧从帧缓存的渲染结果中读取数据，最后通过 AVAssetWriter 将视频文件保存到指定的路径。<br></li>
<li><code>GPUImageView</code>：继承自 UIView，通过输入的纹理，执行一遍渲染流程。我们一般使用它来呈现渲染结果。<br></li>
<li><code>GPUImageTextureOutput</code>：它可以获取到输入的Framebuffer中的纹理对象.<br></li>
<li><code>GPUImageRawDataOutput</code>：通过 rawBytesForImage 属性，可以获取到当前输入纹理的二进制数据。</li>
</ul>
<h6 id="核心功能与方法：-1"><a href="#核心功能与方法：-1" class="headerlink" title="核心功能与方法："></a>核心功能与方法：</h6><p>可以作为滤镜链的终点。基本功能主要包括：</p>
<ul>
<li>接收 GPUmageOutput 的输出信息;</li>
<li>接收上一个GPUImageOutput渲染完成的通知,并且完成自己的处理;</li>
</ul>
<ol>
<li>接收GPUmageOutput的输出信息对应方法：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- (void)setInputFramebuffer:(GPUImageFramebuffer *)newInputFramebuffer atIndex:(NSInteger)textureIndex;</span><br><span class="line">- (NSInteger)nextAvailableTextureIndex;</span><br><span class="line">- (void)setInputSize:(CGSize)newSize atIndex:(NSInteger)textureIndex;</span><br><span class="line">- (void)setInputRotation:(GPUImageRotationMode)newInputRotation atIndex:(NSInteger)textureIndex;</span><br></pre></td></tr></table></figure>
根据这些方法可以看到，GPUImageInput 可以接收的信息包括上一个Output输出的FrameBuffer，FrameBuffer的size以及rotation。这些 textureIndex 都是为了提供个需要多个input的Filter准备的。</li>
<li>接收GPUImageOutput渲染完成的通知对应方法：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (void)newFrameReadyAtTime:(CMTime)frameTime atIndex:(NSInteger)textureIndex;</span><br></pre></td></tr></table></figure>
上一个 GPUImageOutput 渲染完成后会通知它所有的 Target，可以参考下它在<code>GPUImageFilter</code>里面的实现。</li>
</ol>
<h5 id="GPUImageFrameBuffer"><a href="#GPUImageFrameBuffer" class="headerlink" title="GPUImageFrameBuffer"></a><code>GPUImageFrameBuffer</code></h5><p>GPUImageFrameBuffer 提供了在 GPUImageOutput 和 GPUImageInput 进行数据传递的媒介。在整个渲染流程中，GPUImageFrameBuffer作为一个纽带，将各个不同的元素串联起来；每个GPUImageFrameBuffer 都有一个自己的OpenGL Texture，每个 GPUImageOutput 都会输出一个 GPUImageFrameBuffer 对象，而每个 GPUImageInput都实现了一个<code>setInputFramebuffer:atIndex:</code>方法，来接收上一个Output处理完的纹理.</p>
<ul>
<li>GPUImageFrameBuffer 的获取逻辑，是由<code>GPUImageFrameBufferCache</code> 进行管理的，需要时从BufferCache中获取，使用完成后，被BufferCache回收。FrameBuffer 的创建跟存储是需要消耗资源的，所以 GPUImage 为了尽量减少资源的消耗，会将使用完成的 FrameBuffer 存储在缓存中，每次通过 输入的纹理size 跟 TextureOptions 作为 key 从hash map 中获取。</li>
</ul>
<h5 id="GPUImageFilter"><a href="#GPUImageFilter" class="headerlink" title="GPUImageFilter"></a><code>GPUImageFilter</code></h5><p>GPUImageFilter 是整个GPUImage框架的核心,GPUImage所内置的100多种滤镜效果都继承于此类。例如我们经常用到的一些滤镜：</p>
<ul>
<li><code>GPUImageBrightnessFilter</code>:亮度调整滤镜</li>
<li><code>GPUImageExposureFilter</code>:曝光调整滤镜</li>
<li><code>GPUImageContrastFilter</code>:对比度调整滤镜</li>
<li><code>GPUImageSaturationFilter</code>:饱和度调整滤镜</li>
<li><code>GPUImageWhiteBalanceFilter</code>:白平衡调整滤镜</li>
<li><code>GPUImageColorInvertFilter</code>:反转图像的颜色</li>
<li><code>GPUImageCropFilter</code>:将图像裁剪到特定区域</li>
<li><code>GPUImageGaussianBlurFilter</code>:可变半径高斯模糊</li>
<li><code>GPUImageSketchFilter</code>:素描滤镜</li>
<li><code>GPUImageToonFilter</code>:卡通效果</li>
<li><code>GPUImageDissolveBlendFilter</code>:两个图像的混合</li>
<li><code>GPUImageFilterPipeline</code> : 链式组合滤镜<br>…</li>
</ul>
<h6 id="核心功能与方法：-2"><a href="#核心功能与方法：-2" class="headerlink" title="核心功能与方法："></a>核心功能与方法：</h6><ol>
<li><p>GPUImageFilter是GPUImageOutput的子类，但是同时它也实现了GPUImageInput协议。因此，它包含了一个Input和Output的所有功能。既它可以接受一个待渲染对象，渲染完成后继续传递给下一个实现GPUImageInput协议的接受者。具体的方法调用我们在下一小节的 滤镜底层源码分析中讲解。</p>
</li>
<li><p>提供根据不同的顶点着色器(VertexShader)与片元着色器(FragmentShader)来初始化渲染程序(GLProgram)的方法，但是整个渲染过程是一样的，因此这个过程都被封装到了基类中；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- (id)initWithVertexShaderFromString:(NSString *)vertexShaderString fragmentShaderFromString:(NSString *)fragmentShaderString;</span><br><span class="line">- (id)initWithFragmentShaderFromString:(NSString *)fragmentShaderString;</span><br><span class="line">- (id)initWithFragmentShaderFromFile:(NSString *)fragmentShaderFilename;</span><br></pre></td></tr></table></figure>
<p>这里简单介绍一下这几个<code>OPenGL</code>的术语</p>
</li>
</ol>
<ul>
<li><code>VertexShader</code>:顶点着色器，<code>OPenGL</code> 接收用户传递的几何数据（顶点信息和几何图元），这些数据经过顶点着色器后可以确定图形的形状以及位置。顶点着色器是 OPenGL 渲染过程的第一个着色器。</li>
<li>光栅化：是将图形的立体位置转换成在屏幕上显示的像素片元的过程；</li>
<li><code>FragmentShader</code>:对光栅化的像素点进行着色就要使用片元着色器。它是<code>OPenGL</code>渲染过程的最后一个着色器。</li>
<li><code>GLProgram</code>: <code>OpenGL ES</code>的program的面向对象封装,包括了VertexShader，FragmentShader的加载，program的link以及对attribute和uniform的获取和管理.<br>这里主要是一些根据不同的着色器进行创建Program的方法。</li>
</ul>
<ol start="3">
<li>作为基类提供给子类可以进行覆盖的方法。</li>
</ol>
<blockquote>
<p>用一句话来总结GPUImageFilter的作用：就是用来接收源图像(FrameBuffer)，通过自定义的顶点、片元着色器来渲染新的图像，并在绘制完成后通知响应链的下一个对象。</p>
</blockquote>
<h4 id="3-GPUImage滤镜的使用"><a href="#3-GPUImage滤镜的使用" class="headerlink" title="3.GPUImage滤镜的使用"></a>3.GPUImage滤镜的使用</h4><p>我们先来看它的应用效果<br><br><img src="https://i.loli.net/2021/04/25/tqfzpyXRsLCEOUv.gif" alt="效果"><img src="https://i.loli.net/2021/04/25/i3n5zfF8POqR4EG.gif" alt="效果2"></p>
<h5 id="1-为图片添加滤镜"><a href="#1-为图片添加滤镜" class="headerlink" title="(1) 为图片添加滤镜"></a>(1) 为图片添加滤镜</h5><p>直接上代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/**初始化滤镜源头*/</span><br><span class="line"> GPUImagePicture *imagePic = [[GPUImagePicture alloc] initWithImage:[UIImage imageNamed:@&quot;picOne.jpg&quot;]];</span><br><span class="line"> /**创建滤镜*/</span><br><span class="line"> GPUImageGaussianBlurFilter *gaussianBlur = [[GPUImageGaussianBlurFilter alloc] init];</span><br><span class="line"> gaussianBlur.blurRadiusInPixels = 10;</span><br><span class="line"> /**添加接受者，即target*/</span><br><span class="line"> [imagePic addTarget:gaussianBlur];</span><br><span class="line"> /**增加frameBUffer 计数防止被移除*/</span><br><span class="line"> [gaussianBlur useNextFrameForImageCapture];</span><br><span class="line"> /**开始处理图片*/</span><br><span class="line"> [imagePic processImage];</span><br><span class="line"> /**根据frameBuffer 获取图片*/</span><br><span class="line"> self.showImageView.image = [gaussianBlur imageFromCurrentFramebuffer];</span><br></pre></td></tr></table></figure>
<h6 id="流程说明："><a href="#流程说明：" class="headerlink" title="流程说明："></a>流程说明：</h6><ul>
<li>使用图片初始化滤镜源头<code>GPUImagePicture</code></li>
<li>初始化滤镜效果<code>GPUImageGaussianBlurFilter</code></li>
<li>为当前滤镜源添加接收者Target <code>addTarget</code></li>
<li><code>useNextFrameForImageCapture</code>:方法是防止帧缓存被移除，如果不调用这个方法会导致Framebuffer被移除，从而导致Crash</li>
<li>根据滤镜的渲染结果FrameBuffer导出图片<code>[gaussianBlur imageFromCurrentFramebuffer]</code></li>
</ul>
<h5 id="2-摄像头捕获视频流添加滤镜"><a href="#2-摄像头捕获视频流添加滤镜" class="headerlink" title="(2) 摄像头捕获视频流添加滤镜"></a>(2) 摄像头捕获视频流添加滤镜</h5><p>核心代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">- (void)setupCamera</span><br><span class="line">&#123;</span><br><span class="line">    //videoCamera</span><br><span class="line">    self.gpuVideoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPreset640x480 cameraPosition:AVCaptureDevicePositionBack];</span><br><span class="line">    self.gpuVideoCamera.outputImageOrientation = [[UIApplication sharedApplication] statusBarOrientation];</span><br><span class="line">    //GPUImageView填充模式</span><br><span class="line">    self.gpuImageView.fillMode = kGPUImageFillModePreserveAspectRatioAndFill;</span><br><span class="line">    //空白效果</span><br><span class="line">    GPUImageFilter *clearFilter = [[GPUImageFilter alloc] init];</span><br><span class="line">    [self.gpuVideoCamera addTarget:clearFilter];</span><br><span class="line">    [clearFilter addTarget:self.gpuImageView];</span><br><span class="line">    //Start camera capturing, 里面封装的是AVFoundation的session的startRunning</span><br><span class="line">    [self.gpuVideoCamera startCameraCapture];</span><br><span class="line">&#125;</span><br><span class="line">#pragma mark - Action &amp;&amp; Notification</span><br><span class="line">- (IBAction)originalBtnDown:(id)sender &#123;</span><br><span class="line">    /**先移除target*/</span><br><span class="line">    [self.gpuVideoCamera removeAllTargets];</span><br><span class="line">    //空白效果</span><br><span class="line">    GPUImageFilter *clearFilter = [[GPUImageFilter alloc] init];</span><br><span class="line">    [self.gpuVideoCamera addTarget:clearFilter];</span><br><span class="line">    [clearFilter addTarget:self.gpuImageView];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="3-混合滤镜的使用"><a href="#3-混合滤镜的使用" class="headerlink" title="(3) 混合滤镜的使用"></a>(3) 混合滤镜的使用</h5><p>核心代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">GPUImageView *filterView = [[GPUImageView alloc] initWithFrame:self.view.frame];</span><br><span class="line">filterView.center = self.view.center;</span><br><span class="line">filterView.fillMode = kGPUImageFillModePreserveAspectRatioAndFill;</span><br><span class="line">[self.view addSubview:filterView];</span><br><span class="line">/*初始化混合滤镜*/</span><br><span class="line">filter = [[GPUImageDissolveBlendFilter alloc] init];</span><br><span class="line">/*设置滤镜混合度*/</span><br><span class="line">[(GPUImageDissolveBlendFilter *)filter setMix:0.5];</span><br><span class="line">/*初始化视频输出源*/</span><br><span class="line">NSURL *sampleURL = [[NSBundle mainBundle] URLForResource:@&quot;IMG_4278&quot; withExtension:@&quot;MOV&quot;];</span><br><span class="line">movieFile = [[GPUImageMovie alloc] initWithURL:sampleURL];</span><br><span class="line">movieFile.runBenchmark = YES;</span><br><span class="line">movieFile.playAtActualSpeed = YES;</span><br><span class="line">/*初始化摄像头输出源*/</span><br><span class="line">videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:AVCaptureSessionPreset640x480 cameraPosition:AVCaptureDevicePositionBack];</span><br><span class="line">videoCamera.outputImageOrientation = UIInterfaceOrientationPortrait;</span><br><span class="line">NSString *pathToMovie = [NSHomeDirectory() stringByAppendingPathComponent:@&quot;Documents/Movie.m4v&quot;];</span><br><span class="line">unlink([pathToMovie UTF8String]);</span><br><span class="line">NSURL *movieURL = [NSURL fileURLWithPath:pathToMovie];</span><br><span class="line">//初始化接受者</span><br><span class="line">movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:movieURL size:CGSizeMake(480.0, 640.0)];</span><br><span class="line">GPUImageFilter* progressFilter = [[GPUImageFilter alloc] init];</span><br><span class="line">[movieFile addTarget:progressFilter];</span><br><span class="line">//设置输出方向</span><br><span class="line">[progressFilter setInputRotation:kGPUImageRotateRight atIndex:0];</span><br><span class="line">// 响应链</span><br><span class="line">[progressFilter addTarget:filter];</span><br><span class="line">[videoCamera addTarget:filter];</span><br><span class="line">//设置音源</span><br><span class="line"> movieWriter.shouldPassthroughAudio = YES;</span><br><span class="line"> movieFile.audioEncodingTarget = movieWriter;</span><br><span class="line"> [movieFile enableSynchronizedEncodingUsingMovieWriter:movieWriter];</span><br><span class="line"> // 显示到界面</span><br><span class="line">[filter addTarget:filterView];</span><br><span class="line">//添加到接收者</span><br><span class="line">[filter addTarget:movieWriter];</span><br><span class="line">[videoCamera startCameraCapture];</span><br><span class="line">[movieWriter startRecording];</span><br><span class="line">[movieFile startProcessing];</span><br><span class="line">  /*写入结束后保存视频*/</span><br><span class="line">__weak typeof(self) weakSelf = self;</span><br><span class="line">[movieWriter setCompletionBlock:^&#123;</span><br><span class="line">    __strong typeof(self) strongSelf = weakSelf;</span><br><span class="line">    [strongSelf-&gt;filter removeTarget:strongSelf-&gt;movieWriter];</span><br><span class="line">    [strongSelf-&gt;movieWriter finishRecording];</span><br><span class="line">     /*根据movieURL保存视频到本地*/</span><br><span class="line">     // ...</span><br><span class="line"> &#125;];</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="流程说明：-1"><a href="#流程说明：-1" class="headerlink" title="流程说明："></a>流程说明：</h6><ul>
<li>混合滤的核心是<code>GPUImageDissolveBlendFilter</code>的使用，它继承自<code>GPUImageTwoInputFilter</code>,它需要有两个输入源</li>
<li>初始化两个输入源<code>GPUImageVideoCamera</code>跟<code>GPUImageMovie</code></li>
<li>添加输入源到DissolveBlendFilter</li>
<li>添加filter到输出数据源<code>GPUImageMovieWriter</code></li>
</ul>
<h5 id="4-为视频添加水印"><a href="#4-为视频添加水印" class="headerlink" title="(4) 为视频添加水印"></a>(4) 为视频添加水印</h5><p>核心代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">GPUImageView *filterView = [[GPUImageView alloc] initWithFrame:self.view.frame];</span><br><span class="line">self.view = filterView;</span><br><span class="line">// 混合滤镜初始化</span><br><span class="line">filter = [[GPUImageDissolveBlendFilter alloc] init];</span><br><span class="line">//混合度</span><br><span class="line">[(GPUImageDissolveBlendFilter *)filter setMix:0.5];</span><br><span class="line">// 本地视频播放源</span><br><span class="line">NSURL *sampleURL = [[NSBundle mainBundle] URLForResource:@&quot;IMG_4278&quot; withExtension:@&quot;MOV&quot;];</span><br><span class="line">AVAsset *asset = [AVAsset assetWithURL:sampleURL];</span><br><span class="line">CGSize size = self.view.bounds.size;</span><br><span class="line">//设置moive源头</span><br><span class="line">movieFile = [[GPUImageMovie alloc] initWithAsset:asset];</span><br><span class="line">movieFile.runBenchmark = YES;</span><br><span class="line">movieFile.playAtActualSpeed = YES;</span><br><span class="line">// 水印</span><br><span class="line">UILabel *label = [[UILabel alloc] initWithFrame:CGRectMake(100, 100, 100, 100)];</span><br><span class="line">label.text = @&quot;我是水印&quot;;</span><br><span class="line">label.font = [UIFont systemFontOfSize:30];</span><br><span class="line">label.textColor = [UIColor redColor];</span><br><span class="line">[label sizeToFit];</span><br><span class="line">UIImage *image = [UIImage imageNamed:@&quot;watermark.png&quot;];</span><br><span class="line">UIImageView *imageView = [[UIImageView alloc] initWithImage:image];</span><br><span class="line">UIView *subView = [[UIView alloc] initWithFrame:CGRectMake(0, 0, size.width, size.height)];</span><br><span class="line">subView.backgroundColor = [UIColor clearColor];</span><br><span class="line">imageView.center = CGPointMake(subView.bounds.size.width / 2, subView.bounds.size.height / 2);</span><br><span class="line">[subView addSubview:imageView];</span><br><span class="line">[subView addSubview:label];</span><br><span class="line">//设置UI源头</span><br><span class="line">GPUImageUIElement *uielement = [[GPUImageUIElement alloc] initWithView:subView];</span><br><span class="line">//GPUImageTransformFilter 动画的filter</span><br><span class="line">NSString *pathToMovie = [NSHomeDirectory() stringByAppendingPathComponent:@&quot;Documents/Movie.m4v&quot;];</span><br><span class="line">unlink([pathToMovie UTF8String]);</span><br><span class="line">NSURL *movieURL = [NSURL fileURLWithPath:pathToMovie];</span><br><span class="line">//初始化接受者</span><br><span class="line">movieWriter = [[GPUImageMovieWriter alloc] initWithMovieURL:movieURL size:CGSizeMake(480.0, 640.0)];</span><br><span class="line">//为调整视频方向添加一个空白滤镜</span><br><span class="line">GPUImageFilter* progressFilter = [[GPUImageFilter alloc] init];</span><br><span class="line">[movieFile addTarget:progressFilter];</span><br><span class="line">//设置方向</span><br><span class="line">[progressFilter setInputRotation:kGPUImageRotateRight atIndex:0];</span><br><span class="line"></span><br><span class="line">[progressFilter addTarget:filter];</span><br><span class="line">[uielement addTarget:filter];</span><br><span class="line">movieWriter.shouldPassthroughAudio = YES;</span><br><span class="line">movieFile.audioEncodingTarget = movieWriter;</span><br><span class="line">[movieFile enableSynchronizedEncodingUsingMovieWriter:movieWriter];</span><br><span class="line"> // 显示到界面</span><br><span class="line">[filter addTarget:filterView];</span><br><span class="line">[filter addTarget:movieWriter];</span><br><span class="line">//开始记录</span><br><span class="line">[movieWriter startRecording];</span><br><span class="line">[movieFile startProcessing];</span><br><span class="line">__weak typeof(self) weakSelf = self;</span><br><span class="line">//每一帧处理完成 大约30帧/秒</span><br><span class="line">[progressFilter setFrameProcessingCompletionBlock:^(GPUImageOutput *output, CMTime time)&#123;</span><br><span class="line">    CGRect frame = imageView.frame;</span><br><span class="line">    frame.origin.x += 1;</span><br><span class="line">    frame.origin.y += 1;</span><br><span class="line">    imageView.frame = frame;</span><br><span class="line">    //更新UIElement</span><br><span class="line">    [uielement updateWithTimestamp:time];</span><br><span class="line">&#125;];</span><br><span class="line">[movieWriter setCompletionBlock:^&#123;</span><br><span class="line">    __strong typeof(self) strongSelf = weakSelf;</span><br><span class="line">    [strongSelf-&gt;filter removeTarget:strongSelf-&gt;movieWriter];</span><br><span class="line">    [strongSelf-&gt;movieWriter finishRecording];</span><br><span class="line">      /*根据movieURL保存视频到本地*/</span><br><span class="line">     // ... </span><br><span class="line">&#125;];</span><br></pre></td></tr></table></figure>
<h6 id="流程说明：-2"><a href="#流程说明：-2" class="headerlink" title="流程说明："></a>流程说明：</h6><ul>
<li>混合滤镜的核心是<code>GPUImageDissolveBlendFilter</code>的使用，它继承自<code>GPUImageTwoInputFilter</code>,它需要有两个输入源</li>
<li>初始化两个输入源<code>GPUImageVideoCamera</code>跟<code>GPUImageUIElement</code></li>
<li>其他同上</li>
</ul>
<h5 id="5-滤镜组的使用"><a href="#5-滤镜组的使用" class="headerlink" title="(5) 滤镜组的使用"></a>(5) 滤镜组的使用</h5><p>核心代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">//创建摄像头视图</span><br><span class="line">GPUImageView *filterView = [[GPUImageView alloc]initWithFrame:self.view.bounds];</span><br><span class="line">//显示模式充满整个边框</span><br><span class="line">filterView.fillMode = kGPUImageFillModePreserveAspectRatioAndFill;</span><br><span class="line">[self.view addSubview:filterView];</span><br><span class="line">//初始化滤镜源</span><br><span class="line">self.stillCamera = [[GPUImageStillCamera alloc]initWithSessionPreset:AVCaptureSessionPresetPhoto cameraPosition:AVCaptureDevicePositionBack];</span><br><span class="line">//输出图像旋转方式</span><br><span class="line">self.stillCamera.outputImageOrientation = UIInterfaceOrientationPortrait;</span><br><span class="line">//反色滤镜</span><br><span class="line">GPUImageColorInvertFilter *filter1 = [[GPUImageColorInvertFilter alloc]init];</span><br><span class="line">//浮雕滤镜</span><br><span class="line">GPUImageEmbossFilter *filter2 = [[GPUImageEmbossFilter alloc]init];</span><br><span class="line">//GPUImageToonFilter *filter3 = [[GPUImageToonFilter alloc] init];</span><br><span class="line">GPUImageFilterGroup *groupFilter = [[GPUImageFilterGroup alloc]init];</span><br><span class="line">[groupFilter addFilter:filter1];</span><br><span class="line">[groupFilter addFilter:filter2];</span><br><span class="line">//[groupFilter addFilter:filter3];</span><br><span class="line">[filter1 addTarget:filter2];</span><br><span class="line">//[filter2 addTarget:filter3];</span><br><span class="line">//定义了一个变量来保存filter-chain上的最后一个filter,后面保存图片时调用的方法里要用到。</span><br><span class="line">self.lastFilter = filter2;</span><br><span class="line">//设置第一个滤镜</span><br><span class="line">groupFilter.initialFilters = @[filter1];</span><br><span class="line">//设置最后一个滤镜</span><br><span class="line">groupFilter.terminalFilter = filter2;</span><br><span class="line">[self.stillCamera addTarget:groupFilter];</span><br><span class="line">[groupFilter addTarget:filterView];</span><br><span class="line">//解决第一帧黑屏,音频缓冲区是在视频缓冲区之前写入的。</span><br><span class="line">[self.stillCamera addAudioInputsAndOutputs];</span><br><span class="line">[self.view bringSubviewToFront:self.catchBtn];</span><br><span class="line">dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(0.1 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^&#123;</span><br><span class="line">    //开始捕捉</span><br><span class="line">    [self.stillCamera startCameraCapture];</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="流程说明：-3"><a href="#流程说明：-3" class="headerlink" title="流程说明："></a>流程说明：</h6><ul>
<li>混合滤的核心是<code>GPUImageFilterGroup</code>的使用</li>
<li>初始化多个滤镜并且添加到滤镜组</li>
<li>设置Group的第一个以及最后一个滤镜</li>
<li>输出</li>
</ul>
<h3 id="二-GPUImage-底层源码分析"><a href="#二-GPUImage-底层源码分析" class="headerlink" title="二. GPUImage 底层源码分析"></a>二. <code>GPUImage</code> 底层源码分析</h3><h4 id="1-滤镜链加载流程分析"><a href="#1-滤镜链加载流程分析" class="headerlink" title="1.滤镜链加载流程分析"></a>1.滤镜链加载流程分析</h4><p>通过上面的Demo例子我们能够分析滤镜链的使用流程：</p>
<p><img src="https://i.loli.net/2021/04/19/eZsjc9pNyTGOlzW.png" alt="GPUImageFilter流"></p>
<p>接下来我们以图片添加滤镜的例子分析GPUImage的滤镜方法调用流程：</p>
<ul>
<li>使用图片初始化滤镜源头<code>GPUImagePicture</code>,调用方法：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (id)initWithImage:(UIImage *)newImageSource;</span><br></pre></td></tr></table></figure>
这个方法里面又会调用<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">outputFramebuffer = [[GPUImageContext sharedFramebufferCache] fetchFramebufferForSize:pixelSizeToUseForTexture onlyTexture:YES];</span><br></pre></td></tr></table></figure>
这个方法最主要的作用是根据图片的大小去<code>GPUImageFramebufferCache</code>中去获取一块 FrameBuffer,也就是<code>outputFramebuffer</code></li>
<li>滤镜的初始化，根据当前自己的顶点着色器以及片元着色器初始化滤镜，以及创建OPenGL ES的渲染程序 <code>GLProgram</code></li>
<li>为滤镜源添加Target：<code>- (void)addTarget:(id&lt;GPUImageInput&gt;)newTarget;</code>. 在这个方法里面会调用<br><code>[self setInputFramebufferForTarget:newTarget atIndex:textureLocation];</code><br>最终会调用<code>[target setInputFramebuffer:[self framebufferForOutput] atIndex:inputTextureIndex];</code>方法.这个方法最主要的作用是把当前Output的输出 Framebuffer 传递给接受者.</li>
<li><code>- (void)useNextFrameForImageCapture;</code>设置成员变量<code>usingNextFrameForImageCapture = YES</code>代表着输出的结果会被用于获取图像,所以在渲染的核心方法<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (void)renderToTextureWithVertices:(const GLfloat *)vertices textureCoordinates:(const GLfloat *)textureCoordinates;</span><br></pre></td></tr></table></figure>
对<code>outputFramebuffer</code>加锁，因为默认情况下，当下一个input渲染完成之后，就会释放这个 FrameBuffer。如果你需要对当前的Filter的输出进行截图的话，则需要保留住这个 FrameBuffer。</li>
<li>接下来调用方法<code>[imagePic processImage];</code>: 开始进入滤镜处理流程，接着调用方法<code>-(BOOL)processImageWithCompletionHandler:(void (^)(void))completion;</code>在这个方法内部调用了Target的两个方法，进行OutputFrameBuffer的渲染与向下传递.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[currentTarget setInputFramebuffer:outputFramebuffer atIndex:textureIndexOfTarget];</span><br><span class="line">[currentTarget newFrameReadyAtTime:kCMTimeIndefinite atIndex:textureIndexOfTarget];</span><br></pre></td></tr></table></figure>
<p>第一个方法的作用是获取从上个Output传递过来的 Framebuffer，并进行加锁操作。<br><br>第二个方法的作用是利用自身<code>GLProgram</code>进行渲染，并且调用<code>- (void)informTargetsAboutNewFrameAtTime:(CMTime)frameTime;</code>把渲染结果向下一个实现<code>GPUImageInput</code>协议的滤镜传递。</p>
<ul>
<li><code>[gaussianBlur imageFromCurrentFramebuffer];</code> 方法：根据 Framebuffer 获取图片，里面调用<code>- (CGImageRef)newCGImageFromCurrentlyProcessedOutput</code> 方法，完成图片获取以及释放GCD信号量。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (dispatch_semaphore_wait(imageCaptureSemaphore, convertedTimeout) != 0)</span><br><span class="line">  &#123;</span><br><span class="line">        return NULL;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
这里信号量的作用是等待渲染完成。完成后走下面的获取图片流程。整个的方法调用流程可以参考下面的图片：</li>
</ul>
<p><img src="https://i.loli.net/2021/04/21/hu3EyHDFx8voZWq.png" alt="方法调用栈"></p>
<h4 id="2-滤镜渲染流程分析"><a href="#2-滤镜渲染流程分析" class="headerlink" title="2.滤镜渲染流程分析"></a>2.滤镜渲染流程分析</h4><p>渲染是整个<code>GPUImageFilter</code> 的核心，在初始化方法中完成了<code>OpenGL ES Program</code>的创建好并且link成功了之后，我们就可以使用这个Program进行渲染了。整个渲染的过程发生在<code>- (void)renderToTextureWithVertices:textureCoordinates:</code>中。我们也借着解析这个方法来了解一下<code>OpenGL ES</code>的渲染过程：</p>
<ul>
<li><code>[GPUImageContext setActiveShaderProgram:filterProgram];</code>: 将初始化后得到Progrm 上下文设置为默认的context，并且激活。调用的<code>GPUImageContext</code>方法<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+ (void)setActiveShaderProgram:(GLProgram *)shaderProgram;</span><br><span class="line">&#123;</span><br><span class="line">    GPUImageContext *sharedContext = [GPUImageContext sharedImageProcessingContext];</span><br><span class="line">    [sharedContext setContextShaderProgram:shaderProgram];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>获取一个待渲染的<code>GPUImageFrameBuffer</code>,这个FrameBuffer 会根据输入纹理的尺寸(inputTextureSize)以及纹理信息(outputTextureOptions) 去<code>GPUImageFrameBufferCahe</code>中获取。大致流程为：存在符合要求的Framebuffer就返回一个，没有就去创建。</li>
<li>根据<code>usingNextFrameForImageCapture</code>判断当前Framebuffer是否用于获取图片，如果是则进行加锁。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (usingNextFrameForImageCapture)</span><br><span class="line">   &#123; //将这个outputFrameBuffer进行lock。</span><br><span class="line">       [outputFramebuffer lock];</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li>
<li>将整个FrameBuffer的数据使用backgroundColor进行清空：<figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">glClearColor(backgroundColorRed, backgroundColorGreen, backgroundColorBlue, backgroundColorAlpha);</span><br><span class="line">glClear(GL_COLOR_BUFFER_BIT);</span><br></pre></td></tr></table></figure></li>
<li>将上一个Output传递过来的FrameBuffer作为texture用来渲染：<figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">glActiveTexture(GL_TEXTURE2);</span><br><span class="line">glBindTexture(GL_TEXTURE_2D, [firstInputFramebuffer <span class="built_in">texture</span>]);</span><br><span class="line">glUniform1i(filterInputTextureUniform, <span class="number">2</span>);</span><br></pre></td></tr></table></figure></li>
<li>将顶点的位置信息以及顶点的纹理坐标信息作为attribute传递给GPU：<figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">glVertexAttribPointer(filterPositionAttribute, <span class="number">2</span>, GL_FLOAT, <span class="number">0</span>, <span class="number">0</span>, <span class="keyword">vertices</span>);</span><br><span class="line">glVertexAttribPointer(filterTextureCoordinateAttribute, <span class="number">2</span>, GL_FLOAT, <span class="number">0</span>, <span class="number">0</span>, textureCoordinates);</span><br></pre></td></tr></table></figure></li>
<li>进行渲染：<figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">glDrawArrays(GL_TRIANGLE_STRIP, <span class="number">0</span>, <span class="number">4</span>);</span><br></pre></td></tr></table></figure></li>
<li>最后将上一个<code>GPUImageOutput</code>传递过来的FrameBuffer使命已经完成，对其进行解锁释放：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[firstInputFramebuffer unlock];</span><br></pre></td></tr></table></figure>
整个渲染过程完成。</li>
</ul>
<h3 id="三-自定义滤镜"><a href="#三-自定义滤镜" class="headerlink" title="三. 自定义滤镜"></a>三. 自定义滤镜</h3><h4 id="1-如何加载一个自定义滤镜"><a href="#1-如何加载一个自定义滤镜" class="headerlink" title="1.如何加载一个自定义滤镜"></a>1.如何加载一个自定义滤镜</h4><p>通过上面的学习我们知道，滤镜的效果实际是根据不同的顶点着色器以及片元着色器来实现的。是定义滤镜实际就是自定义这两种着色器。有两种方式来加载我们的自定义滤镜</p>
<ul>
<li>自定义滤镜类，继承自<code>GPUImageFilter</code>,然后用字符串常量形式加载我们的Shader代码例如：<figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">NSString *<span class="keyword">const</span> kGPUImageBrightnessFragmentShaderString = SHADER_STRING</span><br><span class="line">(</span><br><span class="line"> <span class="keyword">varying</span> <span class="keyword">highp</span> <span class="type">vec2</span> textureCoordinate;</span><br><span class="line"> <span class="keyword">uniform</span> <span class="type">sampler2D</span> inputImageTexture;</span><br><span class="line"> <span class="keyword">uniform</span> <span class="keyword">lowp</span> <span class="type">float</span> brightness;</span><br><span class="line"> </span><br><span class="line"> <span class="type">void</span> main()</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="keyword">lowp</span> <span class="type">vec4</span> textureColor = <span class="built_in">texture2D</span>(inputImageTexture, textureCoordinate);</span><br><span class="line">     <span class="built_in">gl_FragColor</span> = <span class="type">vec4</span>((textureColor.rgb + <span class="type">vec3</span>(brightness)), textureColor.w);</span><br><span class="line"> &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
然后根据<code>GPUImageFilter</code>提供的初始化方法进行加载。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- (id)initWithVertexShaderFromString:(NSString *)vertexShaderString fragmentShaderFromString:(NSString *)fragmentShaderString;</span><br><span class="line">- (id)initWithFragmentShaderFromString:(NSString *)fragmentShaderString;</span><br><span class="line">- (id)initWithFragmentShaderFromFile:(NSString *)fragmentShaderFilename;</span><br></pre></td></tr></table></figure></li>
<li>另一种方式:如果只是自定义<code>FragmentShader</code>，可以是将Shader语句封装为fsh结尾的文件，然后调用下面方法进行加载<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- (id)initWithFragmentShaderFromFile:(NSString *)fragmentShaderFilename;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="2-一些特殊的自定义滤镜效果"><a href="#2-一些特殊的自定义滤镜效果" class="headerlink" title="2. 一些特殊的自定义滤镜效果"></a>2. 一些特殊的自定义滤镜效果</h4><p><img src="https://i.loli.net/2021/04/25/EFdt6xioV8rGTbw.gif" alt="自定义滤镜"><br><br>一些特殊的滤镜效果,比如抖音的滤镜效果（闪白、灵魂出窍、抖动、缩放、毛刺、眩晕等）可以查看我的<a target="_blank" rel="noopener" href="https://github.com/chenXming/GPUIamage_demo.git">GitHub</a>.<br>关于自定义滤镜部分需要你对<code>OPenGL ES</code>、线性代数以及算法有基础的了解，并且熟悉<code>GLSL着色语言</code>,如果想进一步学习可以参考GLSL的官方快速入门指导<a target="_blank" rel="noopener" href="https://www.khronos.org/opengles/sdk/docs/reference_cards/OpenGL-ES-2_0-Reference-card.pdf">OpenGL ES</a>,我们这篇文章不在涉及。</p>
<h3 id="四-总结"><a href="#四-总结" class="headerlink" title="四. 总结"></a>四. 总结</h3><p>这篇文章主要是介绍了<code>GPUImage</code>的使用、滤镜链加载流程、渲染逻辑，还有一些模块未涉及到，比如<code>GLProgram</code>的创建、link过程,<code>GPUImageMovieComposition</code>视频编辑模块，滤镜的自定义流程等，需要感兴趣的同学自己探究。</p>
<h4 id="1-进一步学习需要掌握的内容"><a href="#1-进一步学习需要掌握的内容" class="headerlink" title="1.进一步学习需要掌握的内容"></a>1.进一步学习需要掌握的内容</h4><p><a target="_blank" rel="noopener" href="http://www.amazon.com/OpenGL-Shading-Language-Randi-Rost/dp/0321637631/ref=sr_1_1?s=books&ie=UTF8&qid=1422896457&sr=1-1&keywords=opengl+shading+language">The OpenGL Shading Language</a><br><br><a target="_blank" rel="noopener" href="http://www.shaderific.com/glsl-functions">GLSL内建的函数介绍</a></p>
<h4 id="2-一些参考引用"><a href="#2-一些参考引用" class="headerlink" title="2.一些参考引用"></a>2.一些参考引用</h4><p><a target="_blank" rel="noopener" href="https://github.com/BradLarson/GPUImage">https://github.com/BradLarson/GPUImage</a><br><br><a target="_blank" rel="noopener" href="https://www.khronos.org/opengles/sdk/docs/reference_cards/OpenGL-ES-2_0-Reference-card.pdf">https://www.khronos.org/opengles/sdk/docs/reference_cards/OpenGL-ES-2_0-Reference-card.pdf</a><br><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/u/8367278ff6cf">https://www.jianshu.com/u/8367278ff6cf</a><br></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://chenxming.github.io/vue-pages/2021/04/25/iOS%E6%BB%A4%E9%95%9C%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/" data-id="clc5nrs860002phexcu5g2j2h" data-title="iOS滤镜那些事儿" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/vue-pages/2022/12/26/hello-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          Hello World
        
      </div>
    </a>
  
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/vue-pages/archives/2022/12/">十二月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/vue-pages/archives/2021/04/">四月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/vue-pages/2022/12/26/%E9%99%88%E5%B0%8F%E6%98%8E%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/">陈小明测试文章</a>
          </li>
        
          <li>
            <a href="/vue-pages/2022/12/26/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/vue-pages/2021/04/25/iOS%E6%BB%A4%E9%95%9C%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/">iOS滤镜那些事儿</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 chenXming<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/vue-pages/" class="mobile-nav-link">Home</a>
  
    <a href="/vue-pages/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/vue-pages/js/jquery-3.4.1.min.js"></script>



  
<script src="/vue-pages/fancybox/jquery.fancybox.min.js"></script>




<script src="/vue-pages/js/script.js"></script>





  </div>
</body>
</html>